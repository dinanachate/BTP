# Architecture de Streaming en Temps RÃ©el

Ce document explique comment fonctionne le systÃ¨me de streaming en temps rÃ©el pour la gÃ©nÃ©ration de cours, incluant la capture des outputs, le systÃ¨me d'Ã©vÃ©nements SSE, et les heartbeats.

---

## Vue d'ensemble : Streaming en Temps RÃ©el avec Thinking Box

L'objectif est de streamer la progression de la gÃ©nÃ©ration de cours vers le client en temps rÃ©el, en affichant les mises Ã  jour dans une "thinking box" tout en maintenant la connexion avec des heartbeats.

---

## 1. SystÃ¨me de Capture des Prints (`orchestrator_with_logging.py`)

### Le ProblÃ¨me
Les agents (retriever, enhancer, generator) utilisent des instructions `print()` pour logger leur progression. Par dÃ©faut, ces messages vont vers stdout et disparaissent.

### La Solution : `StreamingPrintCapture`

```python
class StreamingPrintCapture:
    def __init__(self):
        self.original_stdout = sys.stdout
        self.buffer = []

    def write(self, text):
        self.original_stdout.write(text)  # Continue d'afficher en console
        self.buffer.append(text)          # Sauvegarde aussi le texte

    def get_and_clear(self):
        content = ''.join(self.buffer)
        self.buffer = []
        return content
```

**Comment Ã§a fonctionne :**
1. Remplace `sys.stdout` par notre objet personnalisÃ©
2. Intercepte tous les appels `print()`
3. Stocke les messages dans un buffer
4. RÃ©cupÃ¨re et vide le buffer pÃ©riodiquement

---

## 2. GÃ©nÃ©rateur de Streaming de Progression (`orchestrator_with_logging.py`)

### `stream_course_generation_progress()`

```python
def stream_course_generation_progress(subject, config=None):
    capture = StreamingPrintCapture()
    sys.stdout = capture  # Redirige tous les prints

    try:
        # Phase 1
        print("PHASE 1: RÃ‰CUPÃ‰RATION DES CONNAISSANCES")
        yield {'type': 'progress', 'content': capture.get_and_clear()}

        retriever.retrieve_knowledge(subject)  # Ceci print des messages
        yield {'type': 'progress', 'content': capture.get_and_clear()}

        # Phase 2, 3, etc...

        # RÃ©sultat final
        yield {'type': 'complete', 'results': {...}}
    finally:
        sys.stdout = old_stdout  # Restaure stdout normal
```

**Comment Ã§a fonctionne :**
1. **Capture les prints** : Redirige stdout vers notre capture personnalisÃ©e
2. **Effectue le travail** : Appelle les mÃ©thodes des agents (qui printent la progression)
3. **Yield du texte capturÃ©** : RÃ©cupÃ¨re tous les prints depuis le dernier yield, les envoie
4. **RÃ©pÃ¨te** : AprÃ¨s chaque Ã©tape majeure, yield les logs accumulÃ©s

**Les yields ressemblent Ã  :**
- `{'type': 'progress', 'content': 'ğŸ“š Agent 1 : Collecte...\n'}`
- `{'type': 'complete', 'results': {...}}`

---

## 3. Wrapper de Streaming Asynchrone (`course_service.py`)

### Le ProblÃ¨me
Le gÃ©nÃ©rateur s'exÃ©cute de maniÃ¨re synchrone (bloquante), mais FastAPI est asynchrone. Nous devons :
- ExÃ©cuter le gÃ©nÃ©rateur sans bloquer l'event loop
- Streamer les rÃ©sultats en temps rÃ©el (ne pas attendre la fin)
- Envoyer des heartbeats toutes les 10s

### La Solution : Threading + Queue

```python
async def async_stream_wrapper_with_heartbeat(loop, generator_func, *args, heartbeat_interval=10):
    result_queue = queue.Queue()

    def run_generator():
        # S'exÃ©cute dans un thread en arriÃ¨re-plan
        for item in generator_func(*actual_args):
            result_queue.put(('item', item))  # Met dans la queue immÃ©diatement
        result_queue.put(('done', None))

    thread = threading.Thread(target=run_generator, daemon=True)
    thread.start()  # DÃ©marre le travail en arriÃ¨re-plan

    last_heartbeat = time.time()

    while True:
        # VÃ©rifie si 10 secondes se sont Ã©coulÃ©es â†’ envoie heartbeat
        if time.time() - last_heartbeat >= 10:
            yield {'type': 'heartbeat'}
            last_heartbeat = time.time()

        # VÃ©rifie la queue pour de nouveaux items (non-bloquant)
        result = await loop.run_in_executor(None, get_with_timeout)

        if result:
            yield result  # Yield progress ou complete
        else:
            await asyncio.sleep(0.01)  # Rien dans la queue, attend un peu
```

**Comment Ã§a fonctionne :**

1. **Thread en ArriÃ¨re-plan** :
   - ExÃ©cute `stream_course_generation_progress()`
   - Ne bloque pas l'event loop asynchrone

2. **Communication par Queue** :
   - Le gÃ©nÃ©rateur met des items : `queue.put(('item', {...}))`
   - Le wrapper rÃ©cupÃ¨re des items : `queue.get(timeout=0.1)`
   - Transfert en temps rÃ©el entre le thread et l'async

3. **Timer de Heartbeat** :
   - Suit l'heure du dernier heartbeat
   - Toutes les 10s, yield `{'type': 'heartbeat'}`
   - Maintient la connexion active

4. **Polling Asynchrone** :
   - VÃ©rifie la queue toutes les 0.1s
   - Si vide, dort 0.01s, vÃ©rifie Ã  nouveau
   - Si a un item, le yield immÃ©diatement

---

## 4. Couche Service (`course_service.py`)

### `stream_course_generation()`

```python
async def stream_course_generation(subject, model):
    async for update in async_stream_wrapper_with_heartbeat(...):
        if update['type'] == 'heartbeat':
            # Envoie chunk vide (maintient la connexion)
            yield f"data: {json.dumps({...delta: {}...})}\n\n"

        elif update['type'] == 'progress':
            # Envoie comme reasoning_content (thinking box)
            yield f"data: {json.dumps({...delta: {"reasoning_content": update['content']}...})}\n\n"

        elif update['type'] == 'complete':
            # Envoie le cours markdown final
            yield f"data: {json.dumps({...delta: {"content": markdown}...})}\n\n"
```

**Comment Ã§a fonctionne :**
1. ReÃ§oit les mises Ã  jour du wrapper
2. Convertit en format Server-Sent Events (SSE)
3. Envoie le JSON appropriÃ© selon le type

---

## 5. Format SSE & Affichage Client

### DiffÃ©rents Types de Delta :

**Heartbeat :**
```json
{
  "delta": {},
  "finish_reason": null
}
```
- Maintient la connexion active
- N'affiche rien

**Progression (Thinking Box) :**
```json
{
  "delta": {
    "role": "assistant",
    "reasoning_content": "ğŸ“š Agent 1 : Collecte...\n"
  },
  "finish_reason": null
}
```
- `reasoning_content` â†’ apparaÃ®t dans la thinking box grise
- L'utilisateur voit la progression en temps rÃ©el

**RÃ©ponse Finale :**
```json
{
  "delta": {"content": "# Titre du Cours\n..."},
  "finish_reason": null
}
```
- `content` rÃ©gulier â†’ apparaÃ®t dans la rÃ©ponse principale
- Le markdown du cours rÃ©el

---

## Diagramme de Flux Complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Client envoie une requÃªte                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FastAPI: stream_course_generation()                      â”‚
â”‚    - CrÃ©e le wrapper async avec heartbeat                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Thread en arriÃ¨re-plan dÃ©marre:                          â”‚
â”‚    - stream_course_generation_progress()                    â”‚
â”‚    - Redirige stdout vers capture                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Agent 1: KnowledgeRetrieverAgent                         â”‚
â”‚    print("ğŸ“š Agent 1 : Collecte...")  â†â”€â”€ CapturÃ©           â”‚
â”‚    print("RequÃªte 1/10...")           â†â”€â”€ CapturÃ©           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Le gÃ©nÃ©rateur yield:                                     â”‚
â”‚    yield {'type': 'progress', 'content': texte_capturÃ©}     â”‚
â”‚           â†“ Mis dans la queue                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Le wrapper async poll la queue:                          â”‚
â”‚    - RÃ©cupÃ¨re l'item de la queue                            â”‚
â”‚    - Yield vers la couche service                           â”‚
â”‚    - (Envoie aussi heartbeat toutes les 10s)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Service convertit en SSE:                                â”‚
â”‚    yield "data: {...reasoning_content...}\n\n"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Client reÃ§oit:                                           â”‚
â”‚    - Affiche dans thinking box: "ğŸ“š Agent 1 : Collecte..."  â”‚
â”‚    - Toutes les 10s: heartbeat maintient la connexion       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                     (RÃ©pÃ¨te 4-8 pour chaque phase)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. Le gÃ©nÃ©rateur yield final:                               â”‚
â”‚    yield {'type': 'complete', 'results': {...}}             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. Service envoie markdown comme content:                  â”‚
â”‚     yield "data: {...content: markdown...}\n\n"             â”‚
â”‚     yield "data: [DONE]\n\n"                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## La Connexion Queue : Threading â†” Async

### Le Pont de Communication

Le `queue.Queue()` est le **canal de communication** entre deux contextes d'exÃ©cution diffÃ©rents :

### 1. Thread en ArriÃ¨re-plan (Synchrone/Bloquant)

```python
result_queue = queue.Queue()  # CrÃ©e la queue partagÃ©e

def run_generator():
    for item in generator_func(*actual_args):
        result_queue.put(('item', item))  # â† MET les items dans la queue
    result_queue.put(('done', None))

thread = threading.Thread(target=run_generator)
thread.start()  # S'exÃ©cute dans un thread sÃ©parÃ©
```

**Ce qui se passe :**
- Le thread exÃ©cute `stream_course_generation_progress()`
- Chaque `yield` produit un item
- `result_queue.put()` **met** l'item dans la queue
- Le thread continue Ã  travailler indÃ©pendamment

### 2. Boucle Async Principale (Asynchrone/Non-bloquant)

```python
def get_with_timeout():
    try:
        return result_queue.get(timeout=0.1)  # â† RÃ‰CUPÃˆRE les items de la queue
    except queue.Empty:
        return None

result = await loop.run_in_executor(None, get_with_timeout)
```

**Ce qui se passe :**
- La boucle async appelle `get_with_timeout()` dans l'executor
- `result_queue.get()` **rÃ©cupÃ¨re** les items de la mÃªme queue
- Si la queue a des items â†’ les retourne
- Si la queue est vide â†’ retourne `None` aprÃ¨s timeout de 0.1s

---

## Flux Visuel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 MÃ‰MOIRE PARTAGÃ‰E: queue.Queue()                 â”‚
â”‚                                                                  â”‚
â”‚     [item1] [item2] [item3] ... (FIFO - Premier EntrÃ© Premier Sorti) â”‚
â”‚        â†‘                              â†“                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚ PUT                          â”‚ GET
         â”‚                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  THREAD ARRIÃˆRE-PLAN  â”‚    â”‚   BOUCLE ASYNC         â”‚
â”‚  (Producteur)         â”‚    â”‚   (Consommateur)       â”‚
â”‚                       â”‚    â”‚                        â”‚
â”‚  for item in gen():   â”‚    â”‚  while True:           â”‚
â”‚    queue.put(item) â”€â”€â”€â”¼â”€â”€â”€â–ºâ”‚    result = queue.get()â”‚
â”‚                       â”‚    â”‚    yield result        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Bloquer OK                  Ne doit pas bloquer!
```

---

## Exemple Pas Ã  Pas

### Temps: 0ms
```python
# Le thread dÃ©marre
result_queue = queue.Queue()  # Queue vide: []
```

### Temps: 100ms
```python
# Thread: Agent 1 print quelque chose
yield {'type': 'progress', 'content': 'Agent 1...'}
result_queue.put(('item', {...}))
# Queue maintenant: [('item', {...})]
```

### Temps: 150ms
```python
# Boucle async vÃ©rifie la queue
def get_with_timeout():
    return result_queue.get(timeout=0.1)  # RÃ©cupÃ¨re l'item!

result = await loop.run_in_executor(None, get_with_timeout)
# result = ('item', {...})
# Queue maintenant: [] (vide Ã  nouveau)
```

### Temps: 200ms
```python
# Boucle async vÃ©rifie Ã  nouveau
def get_with_timeout():
    return result_queue.get(timeout=0.1)  # Attend 0.1s, queue toujours vide

result = await loop.run_in_executor(None, get_with_timeout)
# result = None (timeout, pas d'items)
```

### Temps: 500ms
```python
# Thread: Agent 1 termine, yield la prochaine mise Ã  jour
yield {'type': 'progress', 'content': 'TerminÃ©!'}
result_queue.put(('item', {...}))
# Queue maintenant: [('item', {...})]
```

### Temps: 550ms
```python
# Boucle async vÃ©rifie la queue Ã  nouveau
result = await loop.run_in_executor(None, get_with_timeout)
# result = ('item', {...})  â† RÃ©cupÃ©rÃ©!
```

---

## Pourquoi `run_in_executor` ?

```python
result = await loop.run_in_executor(None, get_with_timeout)
```

### Le ProblÃ¨me
`queue.get(timeout=0.1)` est une opÃ©ration **bloquante** :
- Si la queue est vide, elle **bloque** (gÃ¨le) pendant 0.1 secondes
- Bloquer l'event loop async est **mauvais** - Ã§a arrÃªte toutes les autres opÃ©rations async

### La Solution
`run_in_executor(None, func)` exÃ©cute `func` dans un **pool de threads** :
- Le blocage se produit dans un thread sÃ©parÃ©
- L'event loop async reste libre pour faire d'autres choses
- On `await` le rÃ©sultat sans bloquer

**Sans executor (MAUVAIS) :**
```python
result = queue.get(timeout=0.1)  # âŒ Bloque l'event loop pendant 0.1s!
```

**Avec executor (BON) :**
```python
result = await loop.run_in_executor(None, get_with_timeout)
# âœ… Bloque un thread sÃ©parÃ©, l'event loop est libre
```

---

## La Connexion ComplÃ¨te

```python
# 1. CrÃ©e la queue partagÃ©e
result_queue = queue.Queue()

# 2. Le thread met des items DEDANS
def run_generator():
    for item in generator_func():
        result_queue.put(('item', item))  # â† Producteur Ã©crit ici

# 3. Async rÃ©cupÃ¨re les items DEHORS
def get_with_timeout():
    return result_queue.get(timeout=0.1)  # â† Consommateur lit depuis ici

result = await loop.run_in_executor(None, get_with_timeout)
#                                          â†‘
#                          Cette fonction accÃ¨de Ã  la queue!
```

---

## Points ClÃ©s

1. **MÃ©moire PartagÃ©e** : Le thread et la boucle async accÃ¨dent au **mÃªme** objet `result_queue`
2. **Thread-Safe** : `queue.Queue()` est **thread-safe** - sÃ»r Ã  utiliser depuis plusieurs threads
3. **Producteur-Consommateur** : Le thread **produit** (put), async **consomme** (get)
4. **Async Non-Bloquant** : `run_in_executor` empÃªche de bloquer l'event loop
5. **Temps RÃ©el** : Les items circulent dans la queue dÃ¨s qu'ils sont produits

C'est un **pattern producteur-consommateur** classique utilisant une queue thread-safe comme pont de communication!

---

## Concepts ClÃ©s

1. **Capture Stdout** : Intercepte `print()` pour collecter les logs
2. **Pattern GÃ©nÃ©rateur** : `yield` pour streamer les rÃ©sultats de maniÃ¨re incrÃ©mentale
3. **Threading + Queue** : ExÃ©cute du code bloquant sans geler l'async
4. **Heartbeat** : Messages vides basÃ©s sur le temps pour Ã©viter le timeout
5. **Format SSE** : `data: {...}\n\n` pour streamer vers le navigateur
6. **reasoning_content** : Champ spÃ©cial pour l'affichage de la thinking box

Cela crÃ©e une expÃ©rience en temps rÃ©el fluide oÃ¹ les utilisateurs voient exactement ce qui se passe pendant la gÃ©nÃ©ration du cours!
